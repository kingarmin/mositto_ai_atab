{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torch==1.9.0+cu111 in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (1.9.0+cu111)\n",
      "Requirement already satisfied: torchvision==0.10.0+cu111 in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (0.10.0+cu111)\n",
      "Requirement already satisfied: torchaudio==0.9.0 in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (from torch==1.9.0+cu111) (4.5.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (from torchvision==0.10.0+cu111) (1.24.3)\n",
      "Requirement already satisfied: pillow>=5.3.0 in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (from torchvision==0.10.0+cu111) (10.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (0.30.2)\n",
      "Requirement already satisfied: ultralytics in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (8.3.115)\n",
      "Requirement already satisfied: supervision in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (0.25.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (10.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (from huggingface_hub) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (from huggingface_hub) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (from huggingface_hub) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (from huggingface_hub) (4.5.0)\n",
      "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (from ultralytics) (1.24.3)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (from ultralytics) (3.7.5)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (from ultralytics) (1.10.0)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (from ultralytics) (1.9.0+cu111)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (from ultralytics) (0.10.0+cu111)\n",
      "Requirement already satisfied: psutil in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (from ultralytics) (7.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (from ultralytics) (2.0.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: contourpy>=1.0.7 in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (from supervision) (1.1.1)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (from supervision) (0.7.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (6.4.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (from requests->huggingface_hub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (from requests->huggingface_hub) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (from requests->huggingface_hub) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib>=3.3.0->ultralytics) (3.20.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\10.armin\\desktop\\atab\\pro\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub ultralytics supervision pillow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\10.armin\\Desktop\\atab\\pro\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "from ultralytics import YOLO\n",
    "from supervision import Detections\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = hf_hub_download(repo_id=\"arnabdhar/YOLOv8-Face-Detection\", filename=\"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = YOLO(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_frame=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 FACE, 14.4ms\n",
      "Speed: 1.7ms preprocess, 14.4ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 20.1ms\n",
      "Speed: 2.1ms preprocess, 20.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 14.8ms\n",
      "Speed: 2.2ms preprocess, 14.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 12.4ms\n",
      "Speed: 1.5ms preprocess, 12.4ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 12.1ms\n",
      "Speed: 1.9ms preprocess, 12.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 18.2ms\n",
      "Speed: 2.1ms preprocess, 18.2ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 16.8ms\n",
      "Speed: 2.3ms preprocess, 16.8ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 17.5ms\n",
      "Speed: 2.4ms preprocess, 17.5ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 20.0ms\n",
      "Speed: 2.6ms preprocess, 20.0ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 19.4ms\n",
      "Speed: 2.2ms preprocess, 19.4ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 18.3ms\n",
      "Speed: 2.2ms preprocess, 18.3ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 19.8ms\n",
      "Speed: 2.1ms preprocess, 19.8ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 18.3ms\n",
      "Speed: 2.3ms preprocess, 18.3ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 21.3ms\n",
      "Speed: 2.4ms preprocess, 21.3ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 14.8ms\n",
      "Speed: 2.1ms preprocess, 14.8ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 17.2ms\n",
      "Speed: 2.3ms preprocess, 17.2ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 19.7ms\n",
      "Speed: 2.0ms preprocess, 19.7ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 14.6ms\n",
      "Speed: 2.4ms preprocess, 14.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 24.2ms\n",
      "Speed: 2.1ms preprocess, 24.2ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 16.5ms\n",
      "Speed: 2.4ms preprocess, 16.5ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 15.9ms\n",
      "Speed: 2.6ms preprocess, 15.9ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 15.9ms\n",
      "Speed: 1.5ms preprocess, 15.9ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 14.8ms\n",
      "Speed: 2.3ms preprocess, 14.8ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 19.0ms\n",
      "Speed: 2.7ms preprocess, 19.0ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 15.2ms\n",
      "Speed: 2.5ms preprocess, 15.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 11.9ms\n",
      "Speed: 1.8ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 18.0ms\n",
      "Speed: 2.2ms preprocess, 18.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 13.5ms\n",
      "Speed: 1.9ms preprocess, 13.5ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 11.9ms\n",
      "Speed: 2.1ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 13.2ms\n",
      "Speed: 2.3ms preprocess, 13.2ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 17.3ms\n",
      "Speed: 2.4ms preprocess, 17.3ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 18.3ms\n",
      "Speed: 2.8ms preprocess, 18.3ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 17.9ms\n",
      "Speed: 2.1ms preprocess, 17.9ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 16.4ms\n",
      "Speed: 2.2ms preprocess, 16.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 12.5ms\n",
      "Speed: 1.9ms preprocess, 12.5ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 20.0ms\n",
      "Speed: 2.1ms preprocess, 20.0ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 17.9ms\n",
      "Speed: 2.3ms preprocess, 17.9ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 17.3ms\n",
      "Speed: 2.4ms preprocess, 17.3ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 17.1ms\n",
      "Speed: 2.6ms preprocess, 17.1ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 20.7ms\n",
      "Speed: 2.2ms preprocess, 20.7ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 16.6ms\n",
      "Speed: 2.3ms preprocess, 16.6ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 16.6ms\n",
      "Speed: 2.5ms preprocess, 16.6ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 19.5ms\n",
      "Speed: 2.4ms preprocess, 19.5ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 11.8ms\n",
      "Speed: 1.6ms preprocess, 11.8ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 15.4ms\n",
      "Speed: 2.0ms preprocess, 15.4ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 16.1ms\n",
      "Speed: 2.9ms preprocess, 16.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 15.6ms\n",
      "Speed: 2.1ms preprocess, 15.6ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 16.8ms\n",
      "Speed: 2.9ms preprocess, 16.8ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 18.1ms\n",
      "Speed: 3.2ms preprocess, 18.1ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 16.6ms\n",
      "Speed: 2.3ms preprocess, 16.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 17.7ms\n",
      "Speed: 2.9ms preprocess, 17.7ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 16.1ms\n",
      "Speed: 2.4ms preprocess, 16.1ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 17.3ms\n",
      "Speed: 2.1ms preprocess, 17.3ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 20.8ms\n",
      "Speed: 2.6ms preprocess, 20.8ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 18.0ms\n",
      "Speed: 2.6ms preprocess, 18.0ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 16.3ms\n",
      "Speed: 2.5ms preprocess, 16.3ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 18.7ms\n",
      "Speed: 2.5ms preprocess, 18.7ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 20.1ms\n",
      "Speed: 3.5ms preprocess, 20.1ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 15.9ms\n",
      "Speed: 2.5ms preprocess, 15.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 16.4ms\n",
      "Speed: 2.6ms preprocess, 16.4ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 17.0ms\n",
      "Speed: 2.4ms preprocess, 17.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 17.6ms\n",
      "Speed: 2.3ms preprocess, 17.6ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 22.6ms\n",
      "Speed: 2.1ms preprocess, 22.6ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 16.7ms\n",
      "Speed: 2.4ms preprocess, 16.7ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 16.0ms\n",
      "Speed: 2.6ms preprocess, 16.0ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 16.8ms\n",
      "Speed: 2.7ms preprocess, 16.8ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 13.5ms\n",
      "Speed: 2.1ms preprocess, 13.5ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 17.6ms\n",
      "Speed: 2.3ms preprocess, 17.6ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 19.5ms\n",
      "Speed: 2.3ms preprocess, 19.5ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 16.9ms\n",
      "Speed: 2.5ms preprocess, 16.9ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 16.5ms\n",
      "Speed: 3.0ms preprocess, 16.5ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 15.3ms\n",
      "Speed: 2.2ms preprocess, 15.3ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 20.2ms\n",
      "Speed: 2.9ms preprocess, 20.2ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 13.5ms\n",
      "Speed: 1.5ms preprocess, 13.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 FACE, 21.9ms\n",
      "Speed: 2.4ms preprocess, 21.9ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from time import sleep\n",
    "cap=cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"eror\")\n",
    "else:\n",
    "   while(1):\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frame=cv2.flip(frame,1)\n",
    "            output=model(frame)\n",
    "            result = Detections.from_ultralytics(output[0])\n",
    "            if(len(list(map(int,result.area)))!=0):\n",
    "                for i in result.xyxy:\n",
    "                    x1 , y1 , x2 , y2 = map(int , i)\n",
    "                    start_point=(x1 , y1)\n",
    "                    end_point = (x2 , y2)\n",
    "                    cv2.rectangle(frame , start_point , end_point , (255 , 0 , 0) , 2)\n",
    "                    selected_frame.append(frame[y1:y2 , x1:x2])\n",
    "            cv2.imshow(\"AI\",frame) \n",
    "            if cv2.getWindowProperty(\"AI\", cv2.WND_PROP_VISIBLE) < 1:\n",
    "                break  # Exit the loop when the window is closed\n",
    "\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "for idx, crop in enumerate(selected_frame):\n",
    "    if crop.size != 0:  # Make sure crop is valid\n",
    "        cv2.imshow(f\"Crop {idx}\", crop)\n",
    "        key = cv2.waitKey(0)  # Wait until any key is pressed\n",
    "        if key == ord('q'):   # If 'q' pressed, exit early\n",
    "            break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"flower.jpg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x448 (no detections), 35.9ms\n",
      "Speed: 405.9ms preprocess, 35.9ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 448)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(Image.open(image_path))\n",
    "results = Detections.from_ultralytics(output[0])\n",
    "xyxy=[]\n",
    "for i in results.xyxy:\n",
    "    xyxy.append(list(map(int,i)))\n",
    "list(map(int,results.area))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Detections(xyxy=array([[     37.907,      33.984,       98.01,      117.42],\n",
       "       [     181.86,      39.148,       236.9,      109.93]], dtype=float32), mask=None, confidence=array([    0.92732,     0.92277], dtype=float32), class_id=array([0, 0]), tracker_id=None, data={'class_name': array(['FACE', 'FACE'], dtype='<U4')}, metadata={})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pass as real time face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'box': [182, 37, 55, 74],\n",
       "  'confidence': 0.9950318336486816,\n",
       "  'keypoints': {'left_eye': (196, 66),\n",
       "   'right_eye': (223, 67),\n",
       "   'nose': (209, 83),\n",
       "   'mouth_left': (199, 95),\n",
       "   'mouth_right': (218, 95)}},\n",
       " {'box': [39, 37, 57, 76],\n",
       "  'confidence': 0.993867814540863,\n",
       "  'keypoints': {'left_eye': (54, 67),\n",
       "   'right_eye': (81, 67),\n",
       "   'nose': (67, 85),\n",
       "   'mouth_left': (57, 98),\n",
       "   'mouth_right': (78, 98)}}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mtcnn import MTCNN\n",
    "import cv2\n",
    "detector = MTCNN()\n",
    "img = cv2.imread('images.jpg')\n",
    "faces = detector.detect_faces(img)\n",
    "for face in faces:\n",
    "    x, y, w, h = face['box']\n",
    "    cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "cv2.imshow(\"Detected Faces\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (981893717.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[16], line 4\u001b[1;36m\u001b[0m\n\u001b[1;33m    result = DeepFace.verify(img1_path=\"C:\\Users\\10.armin\\Desktop\\atab\\data\\images\\armin ghajari.png\", img2_path=\"C:\\Users\\10.armin\\Desktop\\atab\\data\\images\\messi.jpg\")\u001b[0m\n\u001b[1;37m                                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "from deepface import DeepFace\n",
    "\n",
    "# Compare two faces directly\n",
    "result = DeepFace.verify(img1_path=\"C:\\\\Users\\\\10.armin\\\\Desktop\\\\atab\\\\data\\\\images\\\\armin ghajari.png\", img2_path=\"C:\\\\Users\\\\10.armin\\\\Desktop\\\\atab\\\\data\\\\images\\\\messi.jpg\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## folder searching start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "armin ghajari\n",
      "messi\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path=os.getcwd()+'/data/images'\n",
    "\n",
    "for i in os.listdir(path):\n",
    "    print(i.split(sep='.')[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
